{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading, 892 line(s)\n",
      "\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/titanic/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11827ee80>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 27.7259, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 35 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.3153.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:13:15\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-35\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:13:16\n",
      "INFO:tensorflow:Saving dict for global step 35: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.846369, auc_precision_recall = 0.828443, average_loss = 0.43857, global_step = 35, label/mean = 0.368421, loss = 16.6656, prediction/mean = 0.385613\n",
      "Results at epoch 2\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.846369\n",
      "auc_precision_recall: 0.828443\n",
      "average_loss: 0.43857\n",
      "global_step: 35\n",
      "label/mean: 0.368421\n",
      "loss: 16.6656\n",
      "prediction/mean: 0.385613\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-35\n",
      "INFO:tensorflow:Saving checkpoints for 36 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 14.9244, step = 36\n",
      "INFO:tensorflow:Saving checkpoints for 70 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 30.9898.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:13:24\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-70\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:13:26\n",
      "INFO:tensorflow:Saving dict for global step 70: accuracy = 0.778947, accuracy_baseline = 0.631579, auc = 0.841905, auc_precision_recall = 0.819838, average_loss = 0.449179, global_step = 70, label/mean = 0.368421, loss = 17.0688, prediction/mean = 0.434079\n",
      "Results at epoch 4\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.778947\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.841905\n",
      "auc_precision_recall: 0.819838\n",
      "average_loss: 0.449179\n",
      "global_step: 70\n",
      "label/mean: 0.368421\n",
      "loss: 17.0688\n",
      "prediction/mean: 0.434079\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-70\n",
      "INFO:tensorflow:Saving checkpoints for 71 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 19.551, step = 71\n",
      "INFO:tensorflow:Saving checkpoints for 105 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12.2888.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:13:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-105\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:13:36\n",
      "INFO:tensorflow:Saving dict for global step 105: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.839524, auc_precision_recall = 0.829162, average_loss = 0.436259, global_step = 105, label/mean = 0.368421, loss = 16.5778, prediction/mean = 0.38372\n",
      "Results at epoch 6\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.839524\n",
      "auc_precision_recall: 0.829162\n",
      "average_loss: 0.436259\n",
      "global_step: 105\n",
      "label/mean: 0.368421\n",
      "loss: 16.5778\n",
      "prediction/mean: 0.38372\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-105\n",
      "INFO:tensorflow:Saving checkpoints for 106 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 19.7209, step = 106\n",
      "INFO:tensorflow:Saving checkpoints for 140 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 17.6318.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:13:44\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-140\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:13:45\n",
      "INFO:tensorflow:Saving dict for global step 140: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.83869, auc_precision_recall = 0.827693, average_loss = 0.439541, global_step = 140, label/mean = 0.368421, loss = 16.7026, prediction/mean = 0.396499\n",
      "Results at epoch 8\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.83869\n",
      "auc_precision_recall: 0.827693\n",
      "average_loss: 0.439541\n",
      "global_step: 140\n",
      "label/mean: 0.368421\n",
      "loss: 16.7026\n",
      "prediction/mean: 0.396499\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-140\n",
      "INFO:tensorflow:Saving checkpoints for 141 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 9.71182, step = 141\n",
      "INFO:tensorflow:Saving checkpoints for 175 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 16.5364.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:13:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-175\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:13:56\n",
      "INFO:tensorflow:Saving dict for global step 175: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.837857, auc_precision_recall = 0.825422, average_loss = 0.440484, global_step = 175, label/mean = 0.368421, loss = 16.7384, prediction/mean = 0.348505\n",
      "Results at epoch 10\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.837857\n",
      "auc_precision_recall: 0.825422\n",
      "average_loss: 0.440484\n",
      "global_step: 175\n",
      "label/mean: 0.368421\n",
      "loss: 16.7384\n",
      "prediction/mean: 0.348505\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-175\n",
      "INFO:tensorflow:Saving checkpoints for 176 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 19.4715, step = 176\n",
      "INFO:tensorflow:Saving checkpoints for 210 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 16.1986.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:14:06\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-210\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:14:07\n",
      "INFO:tensorflow:Saving dict for global step 210: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.836845, auc_precision_recall = 0.825136, average_loss = 0.445047, global_step = 210, label/mean = 0.368421, loss = 16.9118, prediction/mean = 0.344836\n",
      "Results at epoch 12\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.836845\n",
      "auc_precision_recall: 0.825136\n",
      "average_loss: 0.445047\n",
      "global_step: 210\n",
      "label/mean: 0.368421\n",
      "loss: 16.9118\n",
      "prediction/mean: 0.344836\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 211 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 16.2289, step = 211\n",
      "INFO:tensorflow:Saving checkpoints for 245 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 23.6805.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:14:16\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-245\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:14:17\n",
      "INFO:tensorflow:Saving dict for global step 245: accuracy = 0.8, accuracy_baseline = 0.631579, auc = 0.840893, auc_precision_recall = 0.832569, average_loss = 0.433951, global_step = 245, label/mean = 0.368421, loss = 16.4901, prediction/mean = 0.398694\n",
      "Results at epoch 14\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.8\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.840893\n",
      "auc_precision_recall: 0.832569\n",
      "average_loss: 0.433951\n",
      "global_step: 245\n",
      "label/mean: 0.368421\n",
      "loss: 16.4901\n",
      "prediction/mean: 0.398694\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-245\n",
      "INFO:tensorflow:Saving checkpoints for 246 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 13.051, step = 246\n",
      "INFO:tensorflow:Saving checkpoints for 280 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 23.6442.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:14:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-280\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:14:27\n",
      "INFO:tensorflow:Saving dict for global step 280: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.836012, auc_precision_recall = 0.823622, average_loss = 0.444261, global_step = 280, label/mean = 0.368421, loss = 16.8819, prediction/mean = 0.334392\n",
      "Results at epoch 16\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.836012\n",
      "auc_precision_recall: 0.823622\n",
      "average_loss: 0.444261\n",
      "global_step: 280\n",
      "label/mean: 0.368421\n",
      "loss: 16.8819\n",
      "prediction/mean: 0.334392\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-280\n",
      "INFO:tensorflow:Saving checkpoints for 281 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 26.7306, step = 281\n",
      "INFO:tensorflow:Saving checkpoints for 315 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 17.9079.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:14:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-315\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:14:36\n",
      "INFO:tensorflow:Saving dict for global step 315: accuracy = 0.815789, accuracy_baseline = 0.631579, auc = 0.838631, auc_precision_recall = 0.826928, average_loss = 0.433567, global_step = 315, label/mean = 0.368421, loss = 16.4755, prediction/mean = 0.373274\n",
      "Results at epoch 18\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.815789\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.838631\n",
      "auc_precision_recall: 0.826928\n",
      "average_loss: 0.433567\n",
      "global_step: 315\n",
      "label/mean: 0.368421\n",
      "loss: 16.4755\n",
      "prediction/mean: 0.373274\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-315\n",
      "INFO:tensorflow:Saving checkpoints for 316 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 13.9362, step = 316\n",
      "INFO:tensorflow:Saving checkpoints for 350 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.1214.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:14:45\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-350\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:14:47\n",
      "INFO:tensorflow:Saving dict for global step 350: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.838929, auc_precision_recall = 0.828167, average_loss = 0.432983, global_step = 350, label/mean = 0.368421, loss = 16.4534, prediction/mean = 0.366431\n",
      "Results at epoch 20\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.838929\n",
      "auc_precision_recall: 0.828167\n",
      "average_loss: 0.432983\n",
      "global_step: 350\n",
      "label/mean: 0.368421\n",
      "loss: 16.4534\n",
      "prediction/mean: 0.366431\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-350\n",
      "INFO:tensorflow:Saving checkpoints for 351 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.069, step = 351\n",
      "INFO:tensorflow:Saving checkpoints for 385 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.3224.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:14:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-385\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:14:56\n",
      "INFO:tensorflow:Saving dict for global step 385: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.809345, auc_precision_recall = 0.781805, average_loss = 0.49639, global_step = 385, label/mean = 0.368421, loss = 18.8628, prediction/mean = 0.295667\n",
      "Results at epoch 22\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.809345\n",
      "auc_precision_recall: 0.781805\n",
      "average_loss: 0.49639\n",
      "global_step: 385\n",
      "label/mean: 0.368421\n",
      "loss: 18.8628\n",
      "prediction/mean: 0.295667\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-385\n",
      "INFO:tensorflow:Saving checkpoints for 386 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 24.8285, step = 386\n",
      "INFO:tensorflow:Saving checkpoints for 420 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.0934.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:15:05\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-420\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:15:06\n",
      "INFO:tensorflow:Saving dict for global step 420: accuracy = 0.815789, accuracy_baseline = 0.631579, auc = 0.84369, auc_precision_recall = 0.832389, average_loss = 0.429206, global_step = 420, label/mean = 0.368421, loss = 16.3098, prediction/mean = 0.376104\n",
      "Results at epoch 24\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.815789\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.84369\n",
      "auc_precision_recall: 0.832389\n",
      "average_loss: 0.429206\n",
      "global_step: 420\n",
      "label/mean: 0.368421\n",
      "loss: 16.3098\n",
      "prediction/mean: 0.376104\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-420\n",
      "INFO:tensorflow:Saving checkpoints for 421 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 11.6549, step = 421\n",
      "INFO:tensorflow:Saving checkpoints for 455 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 12.1821.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:15:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-455\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:15:15\n",
      "INFO:tensorflow:Saving dict for global step 455: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.840774, auc_precision_recall = 0.828211, average_loss = 0.434728, global_step = 455, label/mean = 0.368421, loss = 16.5197, prediction/mean = 0.35402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at epoch 26\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.840774\n",
      "auc_precision_recall: 0.828211\n",
      "average_loss: 0.434728\n",
      "global_step: 455\n",
      "label/mean: 0.368421\n",
      "loss: 16.5197\n",
      "prediction/mean: 0.35402\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-455\n",
      "INFO:tensorflow:Saving checkpoints for 456 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 13.9313, step = 456\n",
      "INFO:tensorflow:Saving checkpoints for 490 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11.4048.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:15:24\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-490\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:15:25\n",
      "INFO:tensorflow:Saving dict for global step 490: accuracy = 0.794737, accuracy_baseline = 0.631579, auc = 0.846667, auc_precision_recall = 0.837146, average_loss = 0.431001, global_step = 490, label/mean = 0.368421, loss = 16.3781, prediction/mean = 0.409789\n",
      "Results at epoch 28\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.794737\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.846667\n",
      "auc_precision_recall: 0.837146\n",
      "average_loss: 0.431001\n",
      "global_step: 490\n",
      "label/mean: 0.368421\n",
      "loss: 16.3781\n",
      "prediction/mean: 0.409789\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-490\n",
      "INFO:tensorflow:Saving checkpoints for 491 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 13.2741, step = 491\n",
      "INFO:tensorflow:Saving checkpoints for 525 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 16.1466.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:15:34\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-525\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:15:35\n",
      "INFO:tensorflow:Saving dict for global step 525: accuracy = 0.815789, accuracy_baseline = 0.631579, auc = 0.844821, auc_precision_recall = 0.832296, average_loss = 0.427613, global_step = 525, label/mean = 0.368421, loss = 16.2493, prediction/mean = 0.374125\n",
      "Results at epoch 30\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.815789\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.844821\n",
      "auc_precision_recall: 0.832296\n",
      "average_loss: 0.427613\n",
      "global_step: 525\n",
      "label/mean: 0.368421\n",
      "loss: 16.2493\n",
      "prediction/mean: 0.374125\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-525\n",
      "INFO:tensorflow:Saving checkpoints for 526 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 12.7337, step = 526\n",
      "INFO:tensorflow:Saving checkpoints for 560 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.2339.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:15:44\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-560\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:15:45\n",
      "INFO:tensorflow:Saving dict for global step 560: accuracy = 0.805263, accuracy_baseline = 0.631579, auc = 0.848036, auc_precision_recall = 0.836203, average_loss = 0.42764, global_step = 560, label/mean = 0.368421, loss = 16.2503, prediction/mean = 0.392422\n",
      "Results at epoch 32\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.805263\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.848036\n",
      "auc_precision_recall: 0.836203\n",
      "average_loss: 0.42764\n",
      "global_step: 560\n",
      "label/mean: 0.368421\n",
      "loss: 16.2503\n",
      "prediction/mean: 0.392422\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-560\n",
      "INFO:tensorflow:Saving checkpoints for 561 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 12.4425, step = 561\n",
      "INFO:tensorflow:Saving checkpoints for 595 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15.9837.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:15:53\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-595\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:15:54\n",
      "INFO:tensorflow:Saving dict for global step 595: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.846964, auc_precision_recall = 0.832838, average_loss = 0.42936, global_step = 595, label/mean = 0.368421, loss = 16.3157, prediction/mean = 0.36317\n",
      "Results at epoch 34\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.846964\n",
      "auc_precision_recall: 0.832838\n",
      "average_loss: 0.42936\n",
      "global_step: 595\n",
      "label/mean: 0.368421\n",
      "loss: 16.3157\n",
      "prediction/mean: 0.36317\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-595\n",
      "INFO:tensorflow:Saving checkpoints for 596 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 13.9962, step = 596\n",
      "INFO:tensorflow:Saving checkpoints for 630 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15.4131.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:16:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-630\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:16:03\n",
      "INFO:tensorflow:Saving dict for global step 630: accuracy = 0.805263, accuracy_baseline = 0.631579, auc = 0.847024, auc_precision_recall = 0.833628, average_loss = 0.428137, global_step = 630, label/mean = 0.368421, loss = 16.2692, prediction/mean = 0.364649\n",
      "Results at epoch 36\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.805263\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.847024\n",
      "auc_precision_recall: 0.833628\n",
      "average_loss: 0.428137\n",
      "global_step: 630\n",
      "label/mean: 0.368421\n",
      "loss: 16.2692\n",
      "prediction/mean: 0.364649\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-630\n",
      "INFO:tensorflow:Saving checkpoints for 631 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 15.0184, step = 631\n",
      "INFO:tensorflow:Saving checkpoints for 665 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20.0079.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:16:11\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-665\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:16:12\n",
      "INFO:tensorflow:Saving dict for global step 665: accuracy = 0.810526, accuracy_baseline = 0.631579, auc = 0.848452, auc_precision_recall = 0.836834, average_loss = 0.425256, global_step = 665, label/mean = 0.368421, loss = 16.1597, prediction/mean = 0.381993\n",
      "Results at epoch 38\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.810526\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.848452\n",
      "auc_precision_recall: 0.836834\n",
      "average_loss: 0.425256\n",
      "global_step: 665\n",
      "label/mean: 0.368421\n",
      "loss: 16.1597\n",
      "prediction/mean: 0.381993\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-665\n",
      "INFO:tensorflow:Saving checkpoints for 666 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 13.1298, step = 666\n",
      "INFO:tensorflow:Saving checkpoints for 700 into /tmp/titanic/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 14.4483.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-15:16:20\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-700\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-15:16:21\n",
      "INFO:tensorflow:Saving dict for global step 700: accuracy = 0.805263, accuracy_baseline = 0.631579, auc = 0.846964, auc_precision_recall = 0.835316, average_loss = 0.426441, global_step = 700, label/mean = 0.368421, loss = 16.2048, prediction/mean = 0.366285\n",
      "Results at epoch 40\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.805263\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.846964\n",
      "auc_precision_recall: 0.835316\n",
      "average_loss: 0.426441\n",
      "global_step: 700\n",
      "label/mean: 0.368421\n",
      "loss: 16.2048\n",
      "prediction/mean: 0.366285\n"
     ]
    }
   ],
   "source": [
    "csv_columns = ['Survived', 'Pclass', 'Sex', 'Age',\n",
    "               'SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "\n",
    "record_defaults = [[0], [0], [''], [0.],\n",
    "                   [0], [0], [0.], ['']]\n",
    "\n",
    "num_examples = 700\n",
    "\n",
    "run_config = tf.estimator.RunConfig().replace(\n",
    "    session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "def build_model_columns():\n",
    "    pclass = tf.feature_column.numeric_column('Pclass', dtype=tf.int32)\n",
    "    sex = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'Sex', ['male', 'female'])\n",
    "    age = tf.feature_column.numeric_column('Age')\n",
    "    age_buckets = tf.feature_column.bucketized_column(\n",
    "        age, boundaries=[5., 10., 18., 30., 40., 50., 60., 65.])\n",
    "    sibsp = tf.feature_column.numeric_column('SibSp', dtype=tf.int32)\n",
    "    parch = tf.feature_column.numeric_column('Parch', dtype=tf.int32)\n",
    "    fare = tf.feature_column.numeric_column('Fare')\n",
    "    cabin = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "      'Cabin', hash_bucket_size=1000)\n",
    "    \n",
    "    return [pclass, sex, age_buckets, sibsp, parch, fare, cabin]\n",
    "\n",
    "def build_estimator():\n",
    "    feature_columns = build_model_columns()\n",
    "\n",
    "    return tf.estimator.LinearClassifier(\n",
    "        model_dir=model_dir,\n",
    "        feature_columns=feature_columns,\n",
    "        config=run_config)\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "\n",
    "    def parse_line(line):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(line, record_defaults=record_defaults)\n",
    "        features = dict(zip(csv_columns, columns))\n",
    "        labels = features.pop('Survived')\n",
    "        return features, tf.equal(labels, 1)\n",
    "\n",
    "    # Extract lines from input files using the Dataset API. | skip(1) ~ means skip header row\n",
    "    dataset = tf.data.TextLineDataset(data_file).skip(1)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=num_examples)\n",
    "\n",
    "    dataset = dataset.map(parse_line, num_parallel_calls=5)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels\n",
    "\n",
    "print(\"loading, \" + str(file_length) + \" line(s)\\n\")\n",
    "\n",
    "# Main \"model\" training\n",
    "train_epochs = 40\n",
    "epochs_per_eval = 2\n",
    "batch_size = 40\n",
    "hidden_units = [100, 75, 50, 25]\n",
    "train_data = 'input/train-main-train-set.csv'\n",
    "test_data = 'input/train-main-dev-set.csv'\n",
    "\n",
    "model_dir = '/tmp/titanic/'\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "model = build_estimator()\n",
    "\n",
    "for n in range(train_epochs // epochs_per_eval):\n",
    "    model.train(input_fn=lambda: input_fn(\n",
    "        train_data, epochs_per_eval, True, batch_size))\n",
    "\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(\n",
    "        test_data, 1, False, batch_size))\n",
    "\n",
    "    # display results\n",
    "\n",
    "    print('Results at epoch', (n + 1) * epochs_per_eval)\n",
    "    print('-' * 60)\n",
    "\n",
    "    for key in sorted(results):\n",
    "        print('%s: %s' % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 1)\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-1401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Survived\n",
       "413         1305        0\n",
       "414         1306        1\n",
       "415         1307        0\n",
       "416         1308        0\n",
       "417         1309        0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model prediction using Pandas and 'tf.estimator.inputs.numpy_input_fn'\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('input/test.csv')\n",
    "pall_pdf = np.array([test_df['Sex']])\n",
    "\n",
    "print(pall_pdf.T.shape)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"Sex\": pall_pdf.T},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "predictions = model.predict(input_fn=predict_input_fn)\n",
    "predicted_classes = [p[\"classes\"][0].decode('utf8') for p in predictions]\n",
    "sum((int(x) for x in predicted_classes))\n",
    "\n",
    "submission = pd.DataFrame(data={'PassengerId': test_df['PassengerId'], 'Survived': predicted_classes})\n",
    "submission.to_csv('input/submission.csv', index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing input/test-main.csv\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-700\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Survived\n",
       "413         1305        0\n",
       "414         1306        1\n",
       "415         1307        0\n",
       "416         1308        0\n",
       "417         1309        0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict with TF\n",
    "\n",
    "csv_columns = ['Pclass', 'Sex', 'Age','SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "record_defaults = [[0], [''], [0.],\n",
    "                   [0], [0], [0.], ['']]\n",
    "\n",
    "\n",
    "def tf_predict_input_fn(data_file):\n",
    "\n",
    "    def parse_csv(value):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "        features = dict(zip(csv_columns, columns))\n",
    "        return features\n",
    "\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = tf.data.TextLineDataset(data_file).skip(1)\n",
    "\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
    "    \n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(1) # times to repeat\n",
    "    dataset = dataset.batch(1) # batch size - NOTE: probably ignored since \"repeat=1\"\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features = iterator.get_next()\n",
    "    return features\n",
    "\n",
    "predictions = model.predict(input_fn=lambda: tf_predict_input_fn(\n",
    "        data_file='input/test-main.csv'))\n",
    "predicted_classes = [p[\"classes\"][0].decode('utf8') for p in predictions]\n",
    "submission = pd.DataFrame(data={\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': predicted_classes\n",
    "})\n",
    "submission.to_csv('input/submission.csv', index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((int(x) for x in predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV - trim down \"train\" feature columns\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/train-orig.csv'\n",
    "write_filename = 'input/train-main.csv'\n",
    "\n",
    "csv_columns = ['Survived', 'Pclass', 'Sex', 'Age',\n",
    "               'SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = csv_columns\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for line in reader:\n",
    "            writer.writerow({c: line[c] for c in csv_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV - split \"all train data\" to: train-set / dev-set\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/train-main.csv'\n",
    "write_filename = 'input/train-main-dev-set.csv'\n",
    "\n",
    "split = 700\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = csv_columns\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for idx, line in enumerate(reader):\n",
    "            if idx > split:\n",
    "                writer.writerow({c: line[c] for c in csv_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set: remove all columns except for 'Sex'\n",
    "# No 'Survived' label like the training data\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/test-orig.csv'\n",
    "write_filename = 'input/test-main.csv'\n",
    "\n",
    "csv_columns = ['Pclass', 'Sex', 'Age',\n",
    "               'SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = csv_columns\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for line in reader:\n",
    "            writer.writerow({c: line[c] for c in csv_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': <tf.Tensor 'DecodeCSV_25:5' shape=() dtype=float32>,\n",
       " 'Cabin': <tf.Tensor 'DecodeCSV_25:10' shape=() dtype=string>,\n",
       " 'Embarked': <tf.Tensor 'DecodeCSV_25:11' shape=() dtype=string>,\n",
       " 'Fare': <tf.Tensor 'DecodeCSV_25:9' shape=() dtype=float32>,\n",
       " 'Name': <tf.Tensor 'DecodeCSV_25:3' shape=() dtype=string>,\n",
       " 'Parch': <tf.Tensor 'DecodeCSV_25:7' shape=() dtype=int32>,\n",
       " 'PassengerId': <tf.Tensor 'DecodeCSV_25:0' shape=() dtype=int32>,\n",
       " 'Pclass': <tf.Tensor 'DecodeCSV_25:2' shape=() dtype=int32>,\n",
       " 'Sex': <tf.Tensor 'DecodeCSV_25:4' shape=() dtype=string>,\n",
       " 'SibSp': <tf.Tensor 'DecodeCSV_25:6' shape=() dtype=int32>,\n",
       " 'Survived': <tf.Tensor 'DecodeCSV_25:1' shape=() dtype=int32>,\n",
       " 'Ticket': <tf.Tensor 'DecodeCSV_25:8' shape=() dtype=string>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-13b4b507778d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Age'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    age = features.pop('Age')\n",
    "except KeyError:\n",
    "    # already poped\n",
    "    pass\n",
    "\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'DecodeCSV_25:1' shape=() dtype=int32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived = features.pop('Survived')\n",
    "survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/titanic/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x114afe6a0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-18456f0fa5a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epochs\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mepochs_per_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     model.train(input_fn=lambda: input_fn(\n\u001b[0m\u001b[1;32m     78\u001b[0m         train_data, epochs_per_eval, True, batch_size))\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 711\u001b[0;31m             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    712\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    254\u001b[0m     super(LinearClassifier, self).__init__(\n\u001b[1;32m    255\u001b[0m         \u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_linear_model_fn\u001b[0;34m(features, labels, mode, head, feature_columns, optimizer, partitioner, config)\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     raise ValueError('features should be a dictionary of `Tensor`s. '\n\u001b[0;32m--> 100\u001b[0;31m                      'Given type: {}'.format(type(features)))\n\u001b[0m\u001b[1;32m    101\u001b[0m   optimizer = optimizers.get_optimizer_instance(\n\u001b[1;32m    102\u001b[0m       \u001b[0moptimizer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "feature_columns = [age]\n",
    "hidden_units = [100, 75, 50, 25]\n",
    "model_dir = '/tmp/titanic/'\n",
    "train_epochs = 10\n",
    "epochs_per_eval = 2\n",
    "batch_size = 50\n",
    "train_data = 'input/train.csv'\n",
    "test_data = 'input/test.csv'\n",
    "num_examples = {\n",
    "    'train': 750,\n",
    "    'test': 891-750\n",
    "}\n",
    "\n",
    "# CSV file and FeatureColumn setup\n",
    "\n",
    "filename = \"input/train.csv\"\n",
    "csv_columns = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex',\n",
    "               'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
    "               'Cabin', 'Embarked']\n",
    "record_defaults = [[0], [0], [0], [''], [''],\n",
    "                   [0.], [0], [0], [''], [0.],\n",
    "                   [''], ['']]\n",
    "\n",
    "# Model Config start\n",
    "\n",
    "run_config = tf.estimator.RunConfig().replace(\n",
    "  session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir,\n",
    "    feature_columns=feature_columns,\n",
    "    config=run_config\n",
    ")\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "\n",
    "    def parse_csv(value):\n",
    "        # setup text reader\n",
    "        file_length = file_len(filename)\n",
    "        filename_queue = tf.train.string_input_producer([filename])\n",
    "        reader = tf.TextLineReader(skip_header_lines=1)\n",
    "        _, csv_row = reader.read(filename_queue)\n",
    "\n",
    "        # setup CSV decoding\n",
    "        passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "\n",
    "        features = dict(zip(\n",
    "            csv_columns,\n",
    "            [passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked]))\n",
    "        age_dict = features.pop('Age')\n",
    "        return [age_dict], tf.equal(survived, 1)\n",
    "\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = tf.data.TextLineDataset(data_file)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=num_examples['train'])\n",
    "\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels\n",
    "\n",
    "# main training run\n",
    "\n",
    "for n in range(train_epochs // epochs_per_eval):\n",
    "    model.train(input_fn=lambda: input_fn(\n",
    "        train_data, epochs_per_eval, True, batch_size))\n",
    "\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(\n",
    "        test_data, 1, False, batch_size))\n",
    "\n",
    "    # Display evaluation metrics\n",
    "    print('Results at epoch', (n + 1) * epochs_per_eval)\n",
    "    print('-' * 60)\n",
    "\n",
    "for key in sorted(results):\n",
    "    print('%s: %s' % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'age_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-85dfc6bf5541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mage_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'age_dict' is not defined"
     ]
    }
   ],
   "source": [
    "age_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
