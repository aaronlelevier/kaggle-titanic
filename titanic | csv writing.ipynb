{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.41999999999999998,\n",
       " 0.67000000000000004,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.82999999999999996,\n",
       " 0.82999999999999996,\n",
       " 0.92000000000000004,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 7.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 11.0,\n",
       " 11.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 13.0,\n",
       " 13.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 14.5,\n",
       " 15.0,\n",
       " 15.0,\n",
       " 15.0,\n",
       " 15.0,\n",
       " 15.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.5,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 23.5,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.5,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 28.5,\n",
       " 28.5,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.5,\n",
       " 30.5,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 32.5,\n",
       " 32.5,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 33.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 34.5,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.5,\n",
       " 37.0,\n",
       " 37.0,\n",
       " 37.0,\n",
       " 37.0,\n",
       " 37.0,\n",
       " 37.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.0,\n",
       " 40.5,\n",
       " 40.5,\n",
       " 41.0,\n",
       " 41.0,\n",
       " 41.0,\n",
       " 41.0,\n",
       " 41.0,\n",
       " 41.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 43.0,\n",
       " 43.0,\n",
       " 43.0,\n",
       " 43.0,\n",
       " 43.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.5,\n",
       " 45.5,\n",
       " 46.0,\n",
       " 46.0,\n",
       " 46.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 48.0,\n",
       " 49.0,\n",
       " 49.0,\n",
       " 49.0,\n",
       " 49.0,\n",
       " 49.0,\n",
       " 49.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 51.0,\n",
       " 51.0,\n",
       " 51.0,\n",
       " 51.0,\n",
       " 51.0,\n",
       " 51.0,\n",
       " 51.0,\n",
       " 52.0,\n",
       " 52.0,\n",
       " 52.0,\n",
       " 52.0,\n",
       " 52.0,\n",
       " 52.0,\n",
       " 53.0,\n",
       " 54.0,\n",
       " 54.0,\n",
       " 54.0,\n",
       " 54.0,\n",
       " 54.0,\n",
       " 54.0,\n",
       " 54.0,\n",
       " 54.0,\n",
       " 55.0,\n",
       " 55.0,\n",
       " 55.5,\n",
       " 56.0,\n",
       " 56.0,\n",
       " 56.0,\n",
       " 56.0,\n",
       " 57.0,\n",
       " 57.0,\n",
       " 58.0,\n",
       " 58.0,\n",
       " 58.0,\n",
       " 58.0,\n",
       " 58.0,\n",
       " 59.0,\n",
       " 59.0,\n",
       " 60.0,\n",
       " 60.0,\n",
       " 60.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 61.0,\n",
       " 61.0,\n",
       " 62.0,\n",
       " 62.0,\n",
       " 62.0,\n",
       " 62.0,\n",
       " 63.0,\n",
       " 63.0,\n",
       " 64.0,\n",
       " 64.0,\n",
       " 65.0,\n",
       " 65.0,\n",
       " 65.0,\n",
       " 66.0,\n",
       " 70.0,\n",
       " 70.0,\n",
       " 70.5,\n",
       " 71.0,\n",
       " 71.0,\n",
       " 74.0,\n",
       " 80.0]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input/train.csv')\n",
    "sorted(df['Age'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading, 892 line(s)\n",
      "\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/titanic/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x116210be0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 27.7259, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 35 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.4846.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:35:43\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-35\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:35:44\n",
      "INFO:tensorflow:Saving dict for global step 35: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.771786, auc_precision_recall = 0.682248, average_loss = 0.51754, global_step = 35, label/mean = 0.368421, loss = 19.6665, prediction/mean = 0.36573\n",
      "Results at epoch 2\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.771786\n",
      "auc_precision_recall: 0.682248\n",
      "average_loss: 0.51754\n",
      "global_step: 35\n",
      "label/mean: 0.368421\n",
      "loss: 19.6665\n",
      "prediction/mean: 0.36573\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-35\n",
      "INFO:tensorflow:Saving checkpoints for 36 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 21.3987, step = 36\n",
      "INFO:tensorflow:Saving checkpoints for 70 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 19.2196.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:35:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-70\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:35:51\n",
      "INFO:tensorflow:Saving dict for global step 70: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.770238, auc_precision_recall = 0.680551, average_loss = 0.516322, global_step = 70, label/mean = 0.368421, loss = 19.6203, prediction/mean = 0.370003\n",
      "Results at epoch 4\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.770238\n",
      "auc_precision_recall: 0.680551\n",
      "average_loss: 0.516322\n",
      "global_step: 70\n",
      "label/mean: 0.368421\n",
      "loss: 19.6203\n",
      "prediction/mean: 0.370003\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-70\n",
      "INFO:tensorflow:Saving checkpoints for 71 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.4173, step = 71\n",
      "INFO:tensorflow:Saving checkpoints for 105 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 21.3208.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:35:57\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-105\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:35:57\n",
      "INFO:tensorflow:Saving dict for global step 105: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772679, auc_precision_recall = 0.68097, average_loss = 0.517195, global_step = 105, label/mean = 0.368421, loss = 19.6534, prediction/mean = 0.379327\n",
      "Results at epoch 6\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772679\n",
      "auc_precision_recall: 0.68097\n",
      "average_loss: 0.517195\n",
      "global_step: 105\n",
      "label/mean: 0.368421\n",
      "loss: 19.6534\n",
      "prediction/mean: 0.379327\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-105\n",
      "INFO:tensorflow:Saving checkpoints for 106 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 19.6816, step = 106\n",
      "INFO:tensorflow:Saving checkpoints for 140 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 25.5664.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-140\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:04\n",
      "INFO:tensorflow:Saving dict for global step 140: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.771786, auc_precision_recall = 0.678171, average_loss = 0.517656, global_step = 140, label/mean = 0.368421, loss = 19.6709, prediction/mean = 0.374797\n",
      "Results at epoch 8\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.771786\n",
      "auc_precision_recall: 0.678171\n",
      "average_loss: 0.517656\n",
      "global_step: 140\n",
      "label/mean: 0.368421\n",
      "loss: 19.6709\n",
      "prediction/mean: 0.374797\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-140\n",
      "INFO:tensorflow:Saving checkpoints for 141 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 15.546, step = 141\n",
      "INFO:tensorflow:Saving checkpoints for 175 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 23.1502.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:09\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-175\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:10\n",
      "INFO:tensorflow:Saving dict for global step 175: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.77125, auc_precision_recall = 0.677481, average_loss = 0.517207, global_step = 175, label/mean = 0.368421, loss = 19.6539, prediction/mean = 0.371164\n",
      "Results at epoch 10\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.77125\n",
      "auc_precision_recall: 0.677481\n",
      "average_loss: 0.517207\n",
      "global_step: 175\n",
      "label/mean: 0.368421\n",
      "loss: 19.6539\n",
      "prediction/mean: 0.371164\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-175\n",
      "INFO:tensorflow:Saving checkpoints for 176 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 22.4121, step = 176\n",
      "INFO:tensorflow:Saving checkpoints for 210 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.3032.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:15\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-210\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:16\n",
      "INFO:tensorflow:Saving dict for global step 210: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.773274, auc_precision_recall = 0.672616, average_loss = 0.517117, global_step = 210, label/mean = 0.368421, loss = 19.6505, prediction/mean = 0.374925\n",
      "Results at epoch 12\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.773274\n",
      "auc_precision_recall: 0.672616\n",
      "average_loss: 0.517117\n",
      "global_step: 210\n",
      "label/mean: 0.368421\n",
      "loss: 19.6505\n",
      "prediction/mean: 0.374925\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-210\n",
      "INFO:tensorflow:Saving checkpoints for 211 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 21.2518, step = 211\n",
      "INFO:tensorflow:Saving checkpoints for 245 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.6425.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:21\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-245\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:23\n",
      "INFO:tensorflow:Saving dict for global step 245: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.774524, auc_precision_recall = 0.674138, average_loss = 0.51717, global_step = 245, label/mean = 0.368421, loss = 19.6524, prediction/mean = 0.375947\n",
      "Results at epoch 14\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.774524\n",
      "auc_precision_recall: 0.674138\n",
      "average_loss: 0.51717\n",
      "global_step: 245\n",
      "label/mean: 0.368421\n",
      "loss: 19.6524\n",
      "prediction/mean: 0.375947\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-245\n",
      "INFO:tensorflow:Saving checkpoints for 246 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.5399, step = 246\n",
      "INFO:tensorflow:Saving checkpoints for 280 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 21.6719.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:28\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-280\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:29\n",
      "INFO:tensorflow:Saving dict for global step 280: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.771548, auc_precision_recall = 0.671772, average_loss = 0.517384, global_step = 280, label/mean = 0.368421, loss = 19.6606, prediction/mean = 0.377037\n",
      "Results at epoch 16\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.771548\n",
      "auc_precision_recall: 0.671772\n",
      "average_loss: 0.517384\n",
      "global_step: 280\n",
      "label/mean: 0.368421\n",
      "loss: 19.6606\n",
      "prediction/mean: 0.377037\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-280\n",
      "INFO:tensorflow:Saving checkpoints for 281 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 21.8543, step = 281\n",
      "INFO:tensorflow:Saving checkpoints for 315 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 19.5192.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-315\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:36\n",
      "INFO:tensorflow:Saving dict for global step 315: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.774702, auc_precision_recall = 0.676362, average_loss = 0.517375, global_step = 315, label/mean = 0.368421, loss = 19.6602, prediction/mean = 0.374192\n",
      "Results at epoch 18\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.774702\n",
      "auc_precision_recall: 0.676362\n",
      "average_loss: 0.517375\n",
      "global_step: 315\n",
      "label/mean: 0.368421\n",
      "loss: 19.6602\n",
      "prediction/mean: 0.374192\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-315\n",
      "INFO:tensorflow:Saving checkpoints for 316 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 16.4085, step = 316\n",
      "INFO:tensorflow:Saving checkpoints for 350 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 21.0164.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:42\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-350\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:43\n",
      "INFO:tensorflow:Saving dict for global step 350: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772024, auc_precision_recall = 0.670266, average_loss = 0.51744, global_step = 350, label/mean = 0.368421, loss = 19.6627, prediction/mean = 0.375313\n",
      "Results at epoch 20\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772024\n",
      "auc_precision_recall: 0.670266\n",
      "average_loss: 0.51744\n",
      "global_step: 350\n",
      "label/mean: 0.368421\n",
      "loss: 19.6627\n",
      "prediction/mean: 0.375313\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-350\n",
      "INFO:tensorflow:Saving checkpoints for 351 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 18.5828, step = 351\n",
      "INFO:tensorflow:Saving checkpoints for 385 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15.9655.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-385\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:50\n",
      "INFO:tensorflow:Saving dict for global step 385: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772381, auc_precision_recall = 0.671758, average_loss = 0.517318, global_step = 385, label/mean = 0.368421, loss = 19.6581, prediction/mean = 0.376251\n",
      "Results at epoch 22\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772381\n",
      "auc_precision_recall: 0.671758\n",
      "average_loss: 0.517318\n",
      "global_step: 385\n",
      "label/mean: 0.368421\n",
      "loss: 19.6581\n",
      "prediction/mean: 0.376251\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-385\n",
      "INFO:tensorflow:Saving checkpoints for 386 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 15.2537, step = 386\n",
      "INFO:tensorflow:Saving checkpoints for 420 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 34.9966.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:36:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-420\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:36:56\n",
      "INFO:tensorflow:Saving dict for global step 420: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.774821, auc_precision_recall = 0.674798, average_loss = 0.517174, global_step = 420, label/mean = 0.368421, loss = 19.6526, prediction/mean = 0.373705\n",
      "Results at epoch 24\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.774821\n",
      "auc_precision_recall: 0.674798\n",
      "average_loss: 0.517174\n",
      "global_step: 420\n",
      "label/mean: 0.368421\n",
      "loss: 19.6526\n",
      "prediction/mean: 0.373705\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-420\n",
      "INFO:tensorflow:Saving checkpoints for 421 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 13.2075, step = 421\n",
      "INFO:tensorflow:Saving checkpoints for 455 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 22.304.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:37:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:37:03\n",
      "INFO:tensorflow:Saving dict for global step 455: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772381, auc_precision_recall = 0.671758, average_loss = 0.517257, global_step = 455, label/mean = 0.368421, loss = 19.6558, prediction/mean = 0.375592\n",
      "Results at epoch 26\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772381\n",
      "auc_precision_recall: 0.671758\n",
      "average_loss: 0.517257\n",
      "global_step: 455\n",
      "label/mean: 0.368421\n",
      "loss: 19.6558\n",
      "prediction/mean: 0.375592\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-455\n",
      "INFO:tensorflow:Saving checkpoints for 456 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 18.179, step = 456\n",
      "INFO:tensorflow:Saving checkpoints for 490 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 28.0864.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:37:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-490\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:37:09\n",
      "INFO:tensorflow:Saving dict for global step 490: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.773214, auc_precision_recall = 0.674308, average_loss = 0.517222, global_step = 490, label/mean = 0.368421, loss = 19.6545, prediction/mean = 0.372707\n",
      "Results at epoch 28\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.773214\n",
      "auc_precision_recall: 0.674308\n",
      "average_loss: 0.517222\n",
      "global_step: 490\n",
      "label/mean: 0.368421\n",
      "loss: 19.6545\n",
      "prediction/mean: 0.372707\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-490\n",
      "INFO:tensorflow:Saving checkpoints for 491 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 16.5816, step = 491\n",
      "INFO:tensorflow:Saving checkpoints for 525 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 23.8877.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:37:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-525\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:37:15\n",
      "INFO:tensorflow:Saving dict for global step 525: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772381, auc_precision_recall = 0.671758, average_loss = 0.517314, global_step = 525, label/mean = 0.368421, loss = 19.6579, prediction/mean = 0.376745\n",
      "Results at epoch 30\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772381\n",
      "auc_precision_recall: 0.671758\n",
      "average_loss: 0.517314\n",
      "global_step: 525\n",
      "label/mean: 0.368421\n",
      "loss: 19.6579\n",
      "prediction/mean: 0.376745\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-525\n",
      "INFO:tensorflow:Saving checkpoints for 526 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 18.0851, step = 526\n",
      "INFO:tensorflow:Saving checkpoints for 560 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 18.9281.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:37:20\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-560\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:37:21\n",
      "INFO:tensorflow:Saving dict for global step 560: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772381, auc_precision_recall = 0.671758, average_loss = 0.517088, global_step = 560, label/mean = 0.368421, loss = 19.6494, prediction/mean = 0.370816\n",
      "Results at epoch 32\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772381\n",
      "auc_precision_recall: 0.671758\n",
      "average_loss: 0.517088\n",
      "global_step: 560\n",
      "label/mean: 0.368421\n",
      "loss: 19.6494\n",
      "prediction/mean: 0.370816\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-560\n",
      "INFO:tensorflow:Saving checkpoints for 561 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.0444, step = 561\n",
      "INFO:tensorflow:Saving checkpoints for 595 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15.3174.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:37:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-595\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:37:27\n",
      "INFO:tensorflow:Saving dict for global step 595: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772381, auc_precision_recall = 0.671758, average_loss = 0.517134, global_step = 595, label/mean = 0.368421, loss = 19.6511, prediction/mean = 0.370865\n",
      "Results at epoch 34\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772381\n",
      "auc_precision_recall: 0.671758\n",
      "average_loss: 0.517134\n",
      "global_step: 595\n",
      "label/mean: 0.368421\n",
      "loss: 19.6511\n",
      "prediction/mean: 0.370865\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-595\n",
      "INFO:tensorflow:Saving checkpoints for 596 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.2867, step = 596\n",
      "INFO:tensorflow:Saving checkpoints for 630 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20.494.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:37:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-630\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:37:33\n",
      "INFO:tensorflow:Saving dict for global step 630: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.773214, auc_precision_recall = 0.674308, average_loss = 0.517171, global_step = 630, label/mean = 0.368421, loss = 19.6525, prediction/mean = 0.37246\n",
      "Results at epoch 36\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.773214\n",
      "auc_precision_recall: 0.674308\n",
      "average_loss: 0.517171\n",
      "global_step: 630\n",
      "label/mean: 0.368421\n",
      "loss: 19.6525\n",
      "prediction/mean: 0.37246\n",
      "Parsing input/train-sex-age-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-630\n",
      "INFO:tensorflow:Saving checkpoints for 631 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.3242, step = 631\n",
      "INFO:tensorflow:Saving checkpoints for 665 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 17.8977.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:37:39\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-665\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:37:39\n",
      "INFO:tensorflow:Saving dict for global step 665: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772381, auc_precision_recall = 0.671758, average_loss = 0.517204, global_step = 665, label/mean = 0.368421, loss = 19.6538, prediction/mean = 0.375105\n",
      "Results at epoch 38\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772381\n",
      "auc_precision_recall: 0.671758\n",
      "average_loss: 0.517204\n",
      "global_step: 665\n",
      "label/mean: 0.368421\n",
      "loss: 19.6538\n",
      "prediction/mean: 0.375105\n",
      "Parsing input/train-sex-age-train-set.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-665\n",
      "INFO:tensorflow:Saving checkpoints for 666 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.3371, step = 666\n",
      "INFO:tensorflow:Saving checkpoints for 700 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 26.0079.\n",
      "Parsing input/train-sex-age-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-20-14:37:45\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-700\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-20-14:37:45\n",
      "INFO:tensorflow:Saving dict for global step 700: accuracy = 0.789474, accuracy_baseline = 0.631579, auc = 0.772381, auc_precision_recall = 0.671758, average_loss = 0.517243, global_step = 700, label/mean = 0.368421, loss = 19.6552, prediction/mean = 0.376108\n",
      "Results at epoch 40\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.789474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.772381\n",
      "auc_precision_recall: 0.671758\n",
      "average_loss: 0.517243\n",
      "global_step: 700\n",
      "label/mean: 0.368421\n",
      "loss: 19.6552\n",
      "prediction/mean: 0.376108\n"
     ]
    }
   ],
   "source": [
    "csv_columns = ['Survived', 'Sex', 'Age']\n",
    "record_defaults = [[0], [''], [0.]]\n",
    "num_examples = {\n",
    "    'train': 700,\n",
    "    'test': 891-700\n",
    "}\n",
    "\n",
    "run_config = tf.estimator.RunConfig().replace(\n",
    "    session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "def build_model_columns():\n",
    "    sex = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'Sex', ['male', 'female'])\n",
    "    age = tf.feature_column.numeric_column('Age')\n",
    "    age_buckets = tf.feature_column.bucketized_column(\n",
    "        age, boundaries=[5., 10., 18., 30., 40., 50., 60., 65.])\n",
    "    return [sex, age_buckets]\n",
    "\n",
    "def build_estimator():\n",
    "    feature_columns = build_model_columns()\n",
    "\n",
    "    return tf.estimator.LinearClassifier(\n",
    "        model_dir=model_dir,\n",
    "        feature_columns=feature_columns,\n",
    "        config=run_config\n",
    "    )\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "\n",
    "    def parse_line(line):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(line, record_defaults=record_defaults)\n",
    "        features = dict(zip(csv_columns, columns))\n",
    "        labels = features.pop('Survived')\n",
    "        return features, tf.equal(labels, 1)\n",
    "\n",
    "    # Extract lines from input files using the Dataset API. | skip(1) ~ means skip header row\n",
    "    dataset = tf.data.TextLineDataset(data_file).skip(1)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=num_examples['train'])\n",
    "\n",
    "    dataset = dataset.map(parse_line, num_parallel_calls=5)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels\n",
    "\n",
    "print(\"loading, \" + str(file_length) + \" line(s)\\n\")\n",
    "\n",
    "# Main \"model\" training\n",
    "train_epochs = 40\n",
    "epochs_per_eval = 2\n",
    "batch_size = 40\n",
    "train_data = 'input/train-sex-age-train-set.csv'\n",
    "test_data = 'input/train-sex-age-dev-set.csv'\n",
    "\n",
    "model_dir = '/tmp/titanic/'\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "model = build_estimator()\n",
    "\n",
    "for n in range(train_epochs // epochs_per_eval):\n",
    "    model.train(input_fn=lambda: input_fn(\n",
    "        train_data, epochs_per_eval, True, batch_size))\n",
    "\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(\n",
    "        test_data, 1, False, batch_size))\n",
    "\n",
    "    # display results\n",
    "\n",
    "    print('Results at epoch', (n + 1) * epochs_per_eval)\n",
    "    print('-' * 60)\n",
    "\n",
    "    for key in sorted(results):\n",
    "        print('%s: %s' % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 1)\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-1401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Survived\n",
       "413         1305        0\n",
       "414         1306        1\n",
       "415         1307        0\n",
       "416         1308        0\n",
       "417         1309        0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model prediction using Pandas and 'tf.estimator.inputs.numpy_input_fn'\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('input/test.csv')\n",
    "pall_pdf = np.array([test_df['Sex']])\n",
    "\n",
    "print(pall_pdf.T.shape)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"Sex\": pall_pdf.T},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "predictions = model.predict(input_fn=predict_input_fn)\n",
    "predicted_classes = [p[\"classes\"][0].decode('utf8') for p in predictions]\n",
    "sum((int(x) for x in predicted_classes))\n",
    "\n",
    "submission = pd.DataFrame(data={'PassengerId': test_df['PassengerId'], 'Survived': predicted_classes})\n",
    "submission.to_csv('input/submission.csv', index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing input/test-sex-age.csv\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-700\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Survived\n",
       "413         1305        0\n",
       "414         1306        1\n",
       "415         1307        0\n",
       "416         1308        0\n",
       "417         1309        0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict with TF\n",
    "def tf_predict_input_fn(data_file):\n",
    "\n",
    "    def parse_csv(value):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(value, record_defaults=[[''], [0.]])\n",
    "        features = dict(zip(['Sex', 'Age'], columns))\n",
    "        return features\n",
    "\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = tf.data.TextLineDataset(data_file).skip(1)\n",
    "\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
    "    \n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(1) # times to repeat\n",
    "    dataset = dataset.batch(1) # batch size - NOTE: probably ignored since \"repeat=1\"\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features = iterator.get_next()\n",
    "    return features\n",
    "\n",
    "predictions = model.predict(input_fn=lambda: tf_predict_input_fn(\n",
    "        data_file='input/test-sex-age.csv'))\n",
    "predicted_classes = [p[\"classes\"][0].decode('utf8') for p in predictions]\n",
    "submission = pd.DataFrame(data={\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': predicted_classes\n",
    "})\n",
    "submission.to_csv('input/submission.csv', index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((int(x) for x in predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV - trim down \"train\" feature columns\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/test-orig.csv'\n",
    "write_filename = 'input/test-sex-age.csv'\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = ['Sex', 'Age']\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for line in reader:\n",
    "            writer.writerow({\n",
    "                'Sex': line['Sex'],\n",
    "                'Age': line['Age']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV - split \"all train data\" to: train-set / dev-set\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/train-sex-age.csv'\n",
    "write_filename = 'input/train-sex-age-train-set.csv'\n",
    "\n",
    "split = 700\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = ['Survived', 'Sex', 'Age']\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for idx, line in enumerate(reader):\n",
    "            if idx < split:\n",
    "                writer.writerow({\n",
    "                    'Survived': line['Survived'],\n",
    "                    'Sex': line['Sex'],\n",
    "                    'Age': line['Age']\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set: remove all columns except for 'Sex'\n",
    "# No 'Survived' label like the training data\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/test-orig.csv'\n",
    "write_filename = 'input/test-sex.csv'\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = ['Sex']\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for line in reader:\n",
    "            writer.writerow({'Sex': line['Sex']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': <tf.Tensor 'DecodeCSV_25:5' shape=() dtype=float32>,\n",
       " 'Cabin': <tf.Tensor 'DecodeCSV_25:10' shape=() dtype=string>,\n",
       " 'Embarked': <tf.Tensor 'DecodeCSV_25:11' shape=() dtype=string>,\n",
       " 'Fare': <tf.Tensor 'DecodeCSV_25:9' shape=() dtype=float32>,\n",
       " 'Name': <tf.Tensor 'DecodeCSV_25:3' shape=() dtype=string>,\n",
       " 'Parch': <tf.Tensor 'DecodeCSV_25:7' shape=() dtype=int32>,\n",
       " 'PassengerId': <tf.Tensor 'DecodeCSV_25:0' shape=() dtype=int32>,\n",
       " 'Pclass': <tf.Tensor 'DecodeCSV_25:2' shape=() dtype=int32>,\n",
       " 'Sex': <tf.Tensor 'DecodeCSV_25:4' shape=() dtype=string>,\n",
       " 'SibSp': <tf.Tensor 'DecodeCSV_25:6' shape=() dtype=int32>,\n",
       " 'Survived': <tf.Tensor 'DecodeCSV_25:1' shape=() dtype=int32>,\n",
       " 'Ticket': <tf.Tensor 'DecodeCSV_25:8' shape=() dtype=string>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-13b4b507778d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Age'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    age = features.pop('Age')\n",
    "except KeyError:\n",
    "    # already poped\n",
    "    pass\n",
    "\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'DecodeCSV_25:1' shape=() dtype=int32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived = features.pop('Survived')\n",
    "survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/titanic/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x114afe6a0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-18456f0fa5a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epochs\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mepochs_per_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     model.train(input_fn=lambda: input_fn(\n\u001b[0m\u001b[1;32m     78\u001b[0m         train_data, epochs_per_eval, True, batch_size))\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 711\u001b[0;31m             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    712\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    254\u001b[0m     super(LinearClassifier, self).__init__(\n\u001b[1;32m    255\u001b[0m         \u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_linear_model_fn\u001b[0;34m(features, labels, mode, head, feature_columns, optimizer, partitioner, config)\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     raise ValueError('features should be a dictionary of `Tensor`s. '\n\u001b[0;32m--> 100\u001b[0;31m                      'Given type: {}'.format(type(features)))\n\u001b[0m\u001b[1;32m    101\u001b[0m   optimizer = optimizers.get_optimizer_instance(\n\u001b[1;32m    102\u001b[0m       \u001b[0moptimizer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "feature_columns = [age]\n",
    "hidden_units = [100, 75, 50, 25]\n",
    "model_dir = '/tmp/titanic/'\n",
    "train_epochs = 10\n",
    "epochs_per_eval = 2\n",
    "batch_size = 50\n",
    "train_data = 'input/train.csv'\n",
    "test_data = 'input/test.csv'\n",
    "num_examples = {\n",
    "    'train': 750,\n",
    "    'test': 891-750\n",
    "}\n",
    "\n",
    "# CSV file and FeatureColumn setup\n",
    "\n",
    "filename = \"input/train.csv\"\n",
    "csv_columns = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex',\n",
    "               'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
    "               'Cabin', 'Embarked']\n",
    "record_defaults = [[0], [0], [0], [''], [''],\n",
    "                   [0.], [0], [0], [''], [0.],\n",
    "                   [''], ['']]\n",
    "\n",
    "# Model Config start\n",
    "\n",
    "run_config = tf.estimator.RunConfig().replace(\n",
    "  session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir,\n",
    "    feature_columns=feature_columns,\n",
    "    config=run_config\n",
    ")\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "\n",
    "    def parse_csv(value):\n",
    "        # setup text reader\n",
    "        file_length = file_len(filename)\n",
    "        filename_queue = tf.train.string_input_producer([filename])\n",
    "        reader = tf.TextLineReader(skip_header_lines=1)\n",
    "        _, csv_row = reader.read(filename_queue)\n",
    "\n",
    "        # setup CSV decoding\n",
    "        passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "\n",
    "        features = dict(zip(\n",
    "            csv_columns,\n",
    "            [passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked]))\n",
    "        age_dict = features.pop('Age')\n",
    "        return [age_dict], tf.equal(survived, 1)\n",
    "\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = tf.data.TextLineDataset(data_file)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=num_examples['train'])\n",
    "\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels\n",
    "\n",
    "# main training run\n",
    "\n",
    "for n in range(train_epochs // epochs_per_eval):\n",
    "    model.train(input_fn=lambda: input_fn(\n",
    "        train_data, epochs_per_eval, True, batch_size))\n",
    "\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(\n",
    "        test_data, 1, False, batch_size))\n",
    "\n",
    "    # Display evaluation metrics\n",
    "    print('Results at epoch', (n + 1) * epochs_per_eval)\n",
    "    print('-' * 60)\n",
    "\n",
    "for key in sorted(results):\n",
    "    print('%s: %s' % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'age_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-85dfc6bf5541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mage_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'age_dict' is not defined"
     ]
    }
   ],
   "source": [
    "age_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
