{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/titanic/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11904c6a0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 78.7212, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 7 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 70.1335.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-25-14:45:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-7\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-25-14:45:50\n",
      "INFO:tensorflow:Saving dict for global step 7: accuracy = 0.389474, accuracy_baseline = 0.631579, auc = 0.739167, auc_precision_recall = 0.665142, average_loss = 0.7241, global_step = 7, label/mean = 0.368421, loss = 68.7895, prediction/mean = 0.632198\n",
      "Results at epoch 1\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.389474\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.739167\n",
      "auc_precision_recall: 0.665142\n",
      "average_loss: 0.7241\n",
      "global_step: 7\n",
      "label/mean: 0.368421\n",
      "loss: 68.7895\n",
      "prediction/mean: 0.632198\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-7\n",
      "INFO:tensorflow:Saving checkpoints for 8 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 95.7376, step = 8\n",
      "INFO:tensorflow:Saving checkpoints for 14 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 65.272.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-25-14:45:58\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-14\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-25-14:45:59\n",
      "INFO:tensorflow:Saving dict for global step 14: accuracy = 0.742105, accuracy_baseline = 0.631579, auc = 0.803214, auc_precision_recall = 0.739207, average_loss = 0.591808, global_step = 14, label/mean = 0.368421, loss = 56.2217, prediction/mean = 0.445538\n",
      "Results at epoch 2\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.742105\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.803214\n",
      "auc_precision_recall: 0.739207\n",
      "average_loss: 0.591808\n",
      "global_step: 14\n",
      "label/mean: 0.368421\n",
      "loss: 56.2217\n",
      "prediction/mean: 0.445538\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-14\n",
      "INFO:tensorflow:Saving checkpoints for 15 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 63.8778, step = 15\n",
      "INFO:tensorflow:Saving checkpoints for 21 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 57.4123.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-25-14:46:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-21\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-25-14:46:09\n",
      "INFO:tensorflow:Saving dict for global step 21: accuracy = 0.631579, accuracy_baseline = 0.631579, auc = 0.815298, auc_precision_recall = 0.75905, average_loss = 0.580657, global_step = 21, label/mean = 0.368421, loss = 55.1625, prediction/mean = 0.233304\n",
      "Results at epoch 3\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.631579\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.815298\n",
      "auc_precision_recall: 0.75905\n",
      "average_loss: 0.580657\n",
      "global_step: 21\n",
      "label/mean: 0.368421\n",
      "loss: 55.1625\n",
      "prediction/mean: 0.233304\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-21\n",
      "INFO:tensorflow:Saving checkpoints for 22 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 60.7505, step = 22\n",
      "INFO:tensorflow:Saving checkpoints for 28 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 63.6431.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-25-14:46:17\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-28\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-25-14:46:18\n",
      "INFO:tensorflow:Saving dict for global step 28: accuracy = 0.631579, accuracy_baseline = 0.631579, auc = 0.759167, auc_precision_recall = 0.664959, average_loss = 0.612393, global_step = 28, label/mean = 0.368421, loss = 58.1773, prediction/mean = 0.244043\n",
      "Results at epoch 4\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.631579\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.759167\n",
      "auc_precision_recall: 0.664959\n",
      "average_loss: 0.612393\n",
      "global_step: 28\n",
      "label/mean: 0.368421\n",
      "loss: 58.1773\n",
      "prediction/mean: 0.244043\n",
      "Parsing input/train-main-train-set.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-28\n",
      "INFO:tensorflow:Saving checkpoints for 29 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:loss = 60.1593, step = 29\n",
      "INFO:tensorflow:Saving checkpoints for 35 into /tmp/titanic/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 61.4805.\n",
      "Parsing input/train-main-dev-set.csv\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-25-14:46:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-35\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-25-14:46:28\n",
      "INFO:tensorflow:Saving dict for global step 35: accuracy = 0.742105, accuracy_baseline = 0.631579, auc = 0.820893, auc_precision_recall = 0.759261, average_loss = 0.499235, global_step = 35, label/mean = 0.368421, loss = 47.4273, prediction/mean = 0.339685\n",
      "Results at epoch 5\n",
      "------------------------------------------------------------\n",
      "accuracy: 0.742105\n",
      "accuracy_baseline: 0.631579\n",
      "auc: 0.820893\n",
      "auc_precision_recall: 0.759261\n",
      "average_loss: 0.499235\n",
      "global_step: 35\n",
      "label/mean: 0.368421\n",
      "loss: 47.4273\n",
      "prediction/mean: 0.339685\n"
     ]
    }
   ],
   "source": [
    "csv_columns = ['Survived', 'Pclass', 'Sex', 'Age',\n",
    "               'SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "\n",
    "record_defaults = [[0], [0], [''], [0.],\n",
    "                   [0], [0], [0.], ['']]\n",
    "\n",
    "num_examples = 700\n",
    "\n",
    "run_config = tf.estimator.RunConfig().replace(\n",
    "    session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "def get_model_columns():\n",
    "    pclass = tf.feature_column.numeric_column('Pclass', dtype=tf.int32)\n",
    "    sex = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'Sex', ['male', 'female'])\n",
    "    age = tf.feature_column.numeric_column('Age')\n",
    "    age_buckets = tf.feature_column.bucketized_column(\n",
    "        age, boundaries=[5., 10., 18., 30., 40., 50., 60., 65.])\n",
    "    sibsp = tf.feature_column.numeric_column('SibSp', dtype=tf.int32)\n",
    "    parch = tf.feature_column.numeric_column('Parch', dtype=tf.int32)\n",
    "    fare = tf.feature_column.numeric_column('Fare')\n",
    "    cabin = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "      'Cabin', hash_bucket_size=1000)\n",
    "    \n",
    "    wide_columns = [pclass, sex, age_buckets, sibsp, parch, fare, cabin]\n",
    "    \n",
    "    dense_sex = tf.feature_column.embedding_column(sex, dimension=2)\n",
    "    dense_cabin = tf.feature_column.embedding_column(cabin, dimension=2)\n",
    "    \n",
    "    deep_columns = [pclass, age_buckets, sibsp, parch, fare, dense_sex, dense_cabin]\n",
    "    \n",
    "    return wide_columns, deep_columns\n",
    "\n",
    "def get_model_classifier(model_type='linear'):\n",
    "    wide_columns, deep_columns = get_model_columns()\n",
    "\n",
    "    if model_type == 'linear':\n",
    "        model = tf.estimator.LinearClassifier(\n",
    "            model_dir=model_dir,\n",
    "            feature_columns=wide_columns,\n",
    "            config=run_config)\n",
    "    elif model_type == 'deep':\n",
    "        model = tf.estimator.DNNClassifier(\n",
    "            model_dir=model_dir,\n",
    "            feature_columns=deep_columns,\n",
    "            hidden_units=hidden_units,\n",
    "            config=run_config)\n",
    "    else:\n",
    "        raise AssertionError('Invalid model type')\n",
    "    return model\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "\n",
    "    def parse_line(line):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(line, record_defaults=record_defaults)\n",
    "        features = dict(zip(csv_columns, columns))\n",
    "        labels = features.pop('Survived')\n",
    "        return features, tf.equal(labels, 1)\n",
    "\n",
    "    # Extract lines from input files using the Dataset API. | skip(1) ~ means skip header row\n",
    "    dataset = tf.data.TextLineDataset(data_file).skip(1)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=num_examples)\n",
    "\n",
    "    dataset = dataset.map(parse_line, num_parallel_calls=5)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels\n",
    "\n",
    "# Main \"model\" training\n",
    "train_epochs = 5\n",
    "epochs_per_eval = 1\n",
    "batch_size = 100\n",
    "hidden_units = [100, 75, 50, 25]\n",
    "train_data = 'input/train-main-train-set.csv'\n",
    "test_data = 'input/train-main-dev-set.csv'\n",
    "\n",
    "model_dir = '/tmp/titanic/'\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "model = get_model_classifier(model_type='deep')\n",
    "\n",
    "results_list = []\n",
    "for n in range(train_epochs // epochs_per_eval):\n",
    "    model.train(input_fn=lambda: input_fn(\n",
    "        train_data, epochs_per_eval, True, batch_size))\n",
    "\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(\n",
    "        test_data, 1, False, batch_size))\n",
    "    results_list.append(results)\n",
    "\n",
    "    # display results\n",
    "\n",
    "    print('Results at epoch', (n + 1) * epochs_per_eval)\n",
    "    print('-' * 60)\n",
    "\n",
    "    for key in sorted(results):\n",
    "        print('%s: %s' % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11390db38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.74210525,\n",
      " 'accuracy_baseline': 0.63157892,\n",
      " 'auc': 0.82089287,\n",
      " 'auc_precision_recall': 0.75926143,\n",
      " 'average_loss': 0.499235,\n",
      " 'global_step': 35,\n",
      " 'label/mean': 0.36842105,\n",
      " 'loss': 47.427326,\n",
      " 'prediction/mean': 0.33968458}\n"
     ]
    }
   ],
   "source": [
    "title = 'Loss'\n",
    "data_points_list = [r['loss'] for r in results_list]\n",
    "\n",
    "plt.ylabel(title)\n",
    "plt.plot(data_points_list)\n",
    "plt.show()\n",
    "\n",
    "pprint.pprint(results_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79473686,\n",
       " 'accuracy_baseline': 0.63157892,\n",
       " 'auc': 0.88327378,\n",
       " 'auc_precision_recall': 0.84986967,\n",
       " 'average_loss': 0.4071424,\n",
       " 'global_step': 280,\n",
       " 'label/mean': 0.36842105,\n",
       " 'loss': 38.678528,\n",
       " 'prediction/mean': 0.33342153}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79473686,\n",
       " 'accuracy_baseline': 0.63157892,\n",
       " 'auc': 0.83946431,\n",
       " 'auc_precision_recall': 0.82736772,\n",
       " 'average_loss': 0.43655688,\n",
       " 'global_step': 40,\n",
       " 'label/mean': 0.36842105,\n",
       " 'loss': 82.945808,\n",
       " 'prediction/mean': 0.39673224}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_40_epochs_700_batch_size = results_list[-1]\n",
    "final_results_20_epochs_40_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 1)\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-1401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Survived\n",
       "413         1305        0\n",
       "414         1306        1\n",
       "415         1307        0\n",
       "416         1308        0\n",
       "417         1309        0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # model prediction using Pandas and 'tf.estimator.inputs.numpy_input_fn'\n",
    "# import pandas as pd\n",
    "\n",
    "# test_df = pd.read_csv('input/test.csv')\n",
    "# pall_pdf = np.array([test_df['Sex']])\n",
    "\n",
    "# print(pall_pdf.T.shape)\n",
    "\n",
    "# predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#     x={\"Sex\": pall_pdf.T},\n",
    "#     num_epochs=1,\n",
    "#     shuffle=False)\n",
    "\n",
    "# predictions = model.predict(input_fn=predict_input_fn)\n",
    "# predicted_classes = [p[\"classes\"][0].decode('utf8') for p in predictions]\n",
    "# sum((int(x) for x in predicted_classes))\n",
    "\n",
    "# submission = pd.DataFrame(data={'PassengerId': test_df['PassengerId'], 'Survived': predicted_classes})\n",
    "# submission.to_csv('input/submission.csv', index=False)\n",
    "# submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing input/test-main.csv\n",
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/titanic/model.ckpt-280\n",
      "Total Survived: 111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Survived\n",
       "413         1305        0\n",
       "414         1306        1\n",
       "415         1307        0\n",
       "416         1308        0\n",
       "417         1309        0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict with TF\n",
    "csv_columns = ['Pclass', 'Sex', 'Age','SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "record_defaults = [[0], [''], [0.],\n",
    "                   [0], [0], [0.], ['']]\n",
    "\n",
    "def tf_predict_input_fn(data_file):\n",
    "\n",
    "    def parse_csv(value):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "        features = dict(zip(csv_columns, columns))\n",
    "        return features\n",
    "\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = tf.data.TextLineDataset(data_file).skip(1)\n",
    "\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
    "    \n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(1) # times to repeat\n",
    "    dataset = dataset.batch(1) # batch size - NOTE: probably ignored since \"repeat=1\"\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features = iterator.get_next()\n",
    "    return features\n",
    "\n",
    "df = pd.read_csv('input/test.csv')\n",
    "\n",
    "predictions = model.predict(input_fn=lambda: tf_predict_input_fn(\n",
    "        data_file='input/test-main.csv'))\n",
    "predicted_classes = [p[\"classes\"][0].decode('utf8') for p in predictions]\n",
    "submission = pd.DataFrame(data={\n",
    "    'PassengerId': df['PassengerId'],\n",
    "    'Survived': predicted_classes\n",
    "})\n",
    "submission.to_csv('input/submission.csv', index=False)\n",
    "\n",
    "print('Total Survived: {}'.format(sum((int(x) for x in predicted_classes))))\n",
    "\n",
    "# Submission CSV tail\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((int(x) for x in predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV - trim down \"train\" feature columns\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/train-orig.csv'\n",
    "write_filename = 'input/train-main.csv'\n",
    "\n",
    "csv_columns = ['Survived', 'Pclass', 'Sex', 'Age',\n",
    "               'SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = csv_columns\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for line in reader:\n",
    "            writer.writerow({c: line[c] for c in csv_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV - split \"all train data\" to: train-set / dev-set\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/train-main.csv'\n",
    "write_filename = 'input/train-main-dev-set.csv'\n",
    "\n",
    "split = 700\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = csv_columns\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for idx, line in enumerate(reader):\n",
    "            if idx > split:\n",
    "                writer.writerow({c: line[c] for c in csv_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set: remove all columns except for 'Sex'\n",
    "# No 'Survived' label like the training data\n",
    "import csv\n",
    "\n",
    "read_filename = 'input/test-orig.csv'\n",
    "write_filename = 'input/test-main.csv'\n",
    "\n",
    "csv_columns = ['Pclass', 'Sex', 'Age',\n",
    "               'SibSp', 'Parch', 'Fare', 'Cabin']\n",
    "\n",
    "with open(read_filename, 'r', newline='') as csv_readfile:\n",
    "    reader = csv.DictReader(csv_readfile)\n",
    "\n",
    "    with open(write_filename, 'w', newline='') as csv_writefile:\n",
    "        fieldnames = csv_columns\n",
    "        writer = csv.DictWriter(csv_writefile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for line in reader:\n",
    "            writer.writerow({c: line[c] for c in csv_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': <tf.Tensor 'DecodeCSV_25:5' shape=() dtype=float32>,\n",
       " 'Cabin': <tf.Tensor 'DecodeCSV_25:10' shape=() dtype=string>,\n",
       " 'Embarked': <tf.Tensor 'DecodeCSV_25:11' shape=() dtype=string>,\n",
       " 'Fare': <tf.Tensor 'DecodeCSV_25:9' shape=() dtype=float32>,\n",
       " 'Name': <tf.Tensor 'DecodeCSV_25:3' shape=() dtype=string>,\n",
       " 'Parch': <tf.Tensor 'DecodeCSV_25:7' shape=() dtype=int32>,\n",
       " 'PassengerId': <tf.Tensor 'DecodeCSV_25:0' shape=() dtype=int32>,\n",
       " 'Pclass': <tf.Tensor 'DecodeCSV_25:2' shape=() dtype=int32>,\n",
       " 'Sex': <tf.Tensor 'DecodeCSV_25:4' shape=() dtype=string>,\n",
       " 'SibSp': <tf.Tensor 'DecodeCSV_25:6' shape=() dtype=int32>,\n",
       " 'Survived': <tf.Tensor 'DecodeCSV_25:1' shape=() dtype=int32>,\n",
       " 'Ticket': <tf.Tensor 'DecodeCSV_25:8' shape=() dtype=string>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-13b4b507778d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Age'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    age = features.pop('Age')\n",
    "except KeyError:\n",
    "    # already poped\n",
    "    pass\n",
    "\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'DecodeCSV_25:1' shape=() dtype=int32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived = features.pop('Survived')\n",
    "survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/titanic/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x114afe6a0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-18456f0fa5a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epochs\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mepochs_per_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     model.train(input_fn=lambda: input_fn(\n\u001b[0m\u001b[1;32m     78\u001b[0m         train_data, epochs_per_eval, True, batch_size))\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 711\u001b[0;31m             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    712\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    254\u001b[0m     super(LinearClassifier, self).__init__(\n\u001b[1;32m    255\u001b[0m         \u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/tensorflow/python/estimator/canned/linear.py\u001b[0m in \u001b[0;36m_linear_model_fn\u001b[0;34m(features, labels, mode, head, feature_columns, optimizer, partitioner, config)\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     raise ValueError('features should be a dictionary of `Tensor`s. '\n\u001b[0;32m--> 100\u001b[0;31m                      'Given type: {}'.format(type(features)))\n\u001b[0m\u001b[1;32m    101\u001b[0m   optimizer = optimizers.get_optimizer_instance(\n\u001b[1;32m    102\u001b[0m       \u001b[0moptimizer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: features should be a dictionary of `Tensor`s. Given type: <class 'tensorflow.python.framework.ops.Tensor'>"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "feature_columns = [age]\n",
    "hidden_units = [100, 75, 50, 25]\n",
    "model_dir = '/tmp/titanic/'\n",
    "train_epochs = 10\n",
    "epochs_per_eval = 2\n",
    "batch_size = 50\n",
    "train_data = 'input/train.csv'\n",
    "test_data = 'input/test.csv'\n",
    "num_examples = {\n",
    "    'train': 750,\n",
    "    'test': 891-750\n",
    "}\n",
    "\n",
    "# CSV file and FeatureColumn setup\n",
    "\n",
    "filename = \"input/train.csv\"\n",
    "csv_columns = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex',\n",
    "               'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
    "               'Cabin', 'Embarked']\n",
    "record_defaults = [[0], [0], [0], [''], [''],\n",
    "                   [0.], [0], [0], [''], [0.],\n",
    "                   [''], ['']]\n",
    "\n",
    "# Model Config start\n",
    "\n",
    "run_config = tf.estimator.RunConfig().replace(\n",
    "  session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir,\n",
    "    feature_columns=feature_columns,\n",
    "    config=run_config\n",
    ")\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "\n",
    "    def parse_csv(value):\n",
    "        # setup text reader\n",
    "        file_length = file_len(filename)\n",
    "        filename_queue = tf.train.string_input_producer([filename])\n",
    "        reader = tf.TextLineReader(skip_header_lines=1)\n",
    "        _, csv_row = reader.read(filename_queue)\n",
    "\n",
    "        # setup CSV decoding\n",
    "        passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = tf.decode_csv(csv_row, record_defaults=record_defaults)\n",
    "\n",
    "        features = dict(zip(\n",
    "            csv_columns,\n",
    "            [passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked]))\n",
    "        age_dict = features.pop('Age')\n",
    "        return [age_dict], tf.equal(survived, 1)\n",
    "\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = tf.data.TextLineDataset(data_file)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=num_examples['train'])\n",
    "\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels\n",
    "\n",
    "# main training run\n",
    "\n",
    "for n in range(train_epochs // epochs_per_eval):\n",
    "    model.train(input_fn=lambda: input_fn(\n",
    "        train_data, epochs_per_eval, True, batch_size))\n",
    "\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(\n",
    "        test_data, 1, False, batch_size))\n",
    "\n",
    "    # Display evaluation metrics\n",
    "    print('Results at epoch', (n + 1) * epochs_per_eval)\n",
    "    print('-' * 60)\n",
    "\n",
    "for key in sorted(results):\n",
    "    print('%s: %s' % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'age_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-85dfc6bf5541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mage_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'age_dict' is not defined"
     ]
    }
   ],
   "source": [
    "age_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pandas' from '/Users/aaron/Documents/ml/kaggle/digit-recognizer/venv/lib/python3.6/site-packages/pandas/__init__.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 13.667], (-0.001, 13.667], (13.667, 24.333], (13.667, 24.333], (24.333, 32.0], (24.333, 32.0]]\n",
       "Categories (3, interval[float64]): [(-0.001, 13.667] < (13.667, 24.333] < (24.333, 32.0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0, 1, 20, 21, 31, 32]\n",
    "\n",
    "pd.qcut(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.666666666666666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = pd.cut(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (-0.032, 10.667]\n",
      "1 (-0.032, 10.667]\n",
      "2 (-0.032, 10.667]\n",
      "3 (-0.032, 10.667]\n",
      "4 (10.667, 21.333]\n",
      "5 (10.667, 21.333]\n",
      "6 (21.333, 32.0]\n",
      "7 (21.333, 32.0]\n"
     ]
    }
   ],
   "source": [
    "a = [0, 1, 3, 4, 20, 21, 31, 32]\n",
    "\n",
    "ret = pd.cut(a, 3)\n",
    "\n",
    "for i, x in enumerate(ret):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'pandas._libs.interval.Interval' and 'pandas._libs.interval.Interval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ae5b33d5d553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'pandas._libs.interval.Interval' and 'pandas._libs.interval.Interval'"
     ]
    }
   ],
   "source": [
    "ret[0] + ret[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
